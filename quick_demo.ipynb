{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick_demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertotrunk/MakeItTalkColabFix/blob/main/quick_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXaL7nU6TEsV"
      },
      "source": [
        "# MakeItTalk Quick Demo (natural human face animation)\n",
        "\n",
        "- included project setup + pretrained model download\n",
        "- provides step-by-step details\n",
        "- todo: tdlr version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2owgbZ22TQmz"
      },
      "source": [
        "## Preparations\n",
        "- Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB-ixde4R3nO",
        "outputId": "745c8b3e-e793-422e-f7cd-8dcdda06fb71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 19 11:31:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0    31W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o31a6SpeTXDM"
      },
      "source": [
        "- Check ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taPSDYiSTcM_"
      },
      "source": [
        "- Install Github https://github.com/yzhou359/MakeItTalk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G0XLqo4SofV",
        "outputId": "cedf19fe-625f-4712-a9d1-9cb807c64161",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/yzhou359/MakeItTalk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MakeItTalk' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xe5u4Ede-G5"
      },
      "source": [
        "- Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR4ExzplfBHk",
        "outputId": "bf490a47-6607-42b1-d380-746620c81900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd MakeItTalk/\n",
        "!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorboardX\n",
        "!pip install -U --no-cache-dir gdown --pre"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MakeItTalk\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.6.0.66)\n",
            "Requirement already satisfied: face_alignment in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (0.25.1)\n",
            "Requirement already satisfied: pynormalize in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (0.1.4)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: pysptk in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: pyworld in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (0.3.2)\n",
            "Requirement already satisfied: resemblyzer in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.1.1.dev0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from face_alignment->-r requirements.txt (line 3)) (4.64.1)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from face_alignment->-r requirements.txt (line 3)) (1.7.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from face_alignment->-r requirements.txt (line 3)) (0.56.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from face_alignment->-r requirements.txt (line 3)) (1.13.1+cu116)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from face_alignment->-r requirements.txt (line 3)) (0.18.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: mutagen>=1.40.0 in /usr/local/lib/python3.8/dist-packages (from pynormalize->-r requirements.txt (line 6)) (1.46.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa->-r requirements.txt (line 8)) (23.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa->-r requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: cython>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from pysptk->-r requirements.txt (line 9)) (0.29.33)\n",
            "Requirement already satisfied: webrtcvad>=2.0.10 in /usr/local/lib/python3.8/dist-packages (from resemblyzer->-r requirements.txt (line 11)) (2.0.10)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.8/dist-packages (from resemblyzer->-r requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 7)) (2.21)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->face_alignment->-r requirements.txt (line 3)) (6.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->face_alignment->-r requirements.txt (line 3)) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->face_alignment->-r requirements.txt (line 3)) (57.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 8)) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa->-r requirements.txt (line 8)) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->face_alignment->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (2023.2.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->face_alignment->-r requirements.txt (line 3)) (3.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->face_alignment->-r requirements.txt (line 3)) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AByGGO5fd14P"
      },
      "source": [
        "- Download pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU4abC3iTmXA",
        "outputId": "77c58d45-4085-4b40-8512-d82e2bd58bc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir examples/dump\n",
        "!mkdir examples/ckpt\n",
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!pip install gdown\n",
        "!gdown -O examples/ckpt/ckpt_autovc.pth 1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
        "!gdown -O examples/ckpt/ckpt_content_branch.pth 1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
        "!gdown -O examples/ckpt/ckpt_speaker_branch.pth 1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
        "!gdown -O examples/ckpt/ckpt_116_i2i_comb.pth 1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
        "!gdown -O examples/dump/emb.pickle 18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘examples/dump’: File exists\n",
            "mkdir: cannot create directory ‘examples/ckpt’: File exists\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_autovc.pth\n",
            "100% 172M/172M [00:01<00:00, 129MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_content_branch.pth\n",
            "100% 7.88M/7.88M [00:00<00:00, 83.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_speaker_branch.pth\n",
            "100% 15.4M/15.4M [00:00<00:00, 48.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a\n",
            "To: /content/MakeItTalk/examples/ckpt/ckpt_116_i2i_comb.pth\n",
            "100% 839M/839M [00:05<00:00, 161MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI\n",
            "To: /content/MakeItTalk/examples/dump/emb.pickle\n",
            "100% 30.9M/30.9M [00:00<00:00, 235MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37JeD3ZZdI-a"
      },
      "source": [
        "- prepare your images/audios (or you can use the existing ones)\n",
        "  - An image to animate: upload to `MakeItTalk/examples` folder, image size should be 256x256\n",
        "  - An audio (hopefully no noise) to talk: upload to `MakeItTalk/examples` folder as well\n",
        "\n",
        "## Step 0: import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olj6VcfiTrd_"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"thirdparty/AdaptiveWingLoss\")\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import argparse\n",
        "from src.approaches.train_image_translation import Image_translation_block\n",
        "import torch\n",
        "import pickle\n",
        "import face_alignment\n",
        "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor\n",
        "import shutil\n",
        "import time\n",
        "import util.utils as util\n",
        "from scipy.signal import savgol_filter\n",
        "from src.approaches.train_audio2landmark import Audio2landmark_model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8aaCE6vgmXy"
      },
      "source": [
        "## Step 1: Basic setup for the animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58s-c9H8dWPW"
      },
      "source": [
        "default_head_name = 'paint_boy'           # the image name (with no .jpg) to animate\n",
        "ADD_NAIVE_EYE = True                 # whether add naive eye blink\n",
        "CLOSE_INPUT_FACE_MOUTH = False       # if your image has an opened mouth, put this as True, else False\n",
        "AMP_LIP_SHAPE_X = 2.                 # amplify the lip motion in horizontal direction\n",
        "AMP_LIP_SHAPE_Y = 2.                 # amplify the lip motion in vertical direction\n",
        "AMP_HEAD_POSE_MOTION = 0.7           # amplify the head pose motion (usually smaller than 1.0, put it to 0. for a static head pose)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRFBOqXMguSH"
      },
      "source": [
        "Default hyper-parameters for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkZRYLSCf8TK"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--jpg', type=str, default='{}.jpg'.format(default_head_name))\n",
        "parser.add_argument('--close_input_face_mouth', default=CLOSE_INPUT_FACE_MOUTH, action='store_true')\n",
        "\n",
        "parser.add_argument('--load_AUTOVC_name', type=str, default='examples/ckpt/ckpt_autovc.pth')\n",
        "parser.add_argument('--load_a2l_G_name', type=str, default='examples/ckpt/ckpt_speaker_branch.pth')\n",
        "parser.add_argument('--load_a2l_C_name', type=str, default='examples/ckpt/ckpt_content_branch.pth') #ckpt_audio2landmark_c.pth')\n",
        "parser.add_argument('--load_G_name', type=str, default='examples/ckpt/ckpt_116_i2i_comb.pth') #ckpt_image2image.pth') #ckpt_i2i_finetune_150.pth') #c\n",
        "\n",
        "parser.add_argument('--amp_lip_x', type=float, default=AMP_LIP_SHAPE_X)\n",
        "parser.add_argument('--amp_lip_y', type=float, default=AMP_LIP_SHAPE_Y)\n",
        "parser.add_argument('--amp_pos', type=float, default=AMP_HEAD_POSE_MOTION)\n",
        "parser.add_argument('--reuse_train_emb_list', type=str, nargs='+', default=[]) #  ['iWeklsXc0H8']) #['45hn7-LXDX8']) #['E_kmpT-EfOg']) #'iWeklsXc0H8', '29k8RtSUjE0', '45hn7-LXDX8',\n",
        "parser.add_argument('--add_audio_in', default=False, action='store_true')\n",
        "parser.add_argument('--comb_fan_awing', default=False, action='store_true')\n",
        "parser.add_argument('--output_folder', type=str, default='examples')\n",
        "\n",
        "parser.add_argument('--test_end2end', default=True, action='store_true')\n",
        "parser.add_argument('--dump_dir', type=str, default='', help='')\n",
        "parser.add_argument('--pos_dim', default=7, type=int)\n",
        "parser.add_argument('--use_prior_net', default=True, action='store_true')\n",
        "parser.add_argument('--transformer_d_model', default=32, type=int)\n",
        "parser.add_argument('--transformer_N', default=2, type=int)\n",
        "parser.add_argument('--transformer_heads', default=2, type=int)\n",
        "parser.add_argument('--spk_emb_enc_size', default=16, type=int)\n",
        "parser.add_argument('--init_content_encoder', type=str, default='')\n",
        "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
        "parser.add_argument('--reg_lr', type=float, default=1e-6, help='weight decay')\n",
        "parser.add_argument('--write', default=False, action='store_true')\n",
        "parser.add_argument('--segment_batch_size', type=int, default=1, help='batch size')\n",
        "parser.add_argument('--emb_coef', default=3.0, type=float)\n",
        "parser.add_argument('--lambda_laplacian_smooth_loss', default=1.0, type=float)\n",
        "parser.add_argument('--use_11spk_only', default=False, action='store_true')\n",
        "parser.add_argument('-f')\n",
        "\n",
        "opt_parser = parser.parse_args()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qchIUwTTg3AB"
      },
      "source": [
        "## Step 2: load the image and detect its landmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmYcSmrugxQK",
        "outputId": "3df8c97a-7212-4aca-c4ae-8a432acfe995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "img =cv2.imread('examples/' + opt_parser.jpg)\n",
        "predictor = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, device='cpu', flip_input=True)\n",
        "shapes = predictor.get_landmarks(img)\n",
        "if (not shapes or len(shapes) != 1):\n",
        "    print('Cannot detect face landmarks. Exit.')\n",
        "    exit(-1)\n",
        "shape_3d = shapes[0]\n",
        "\n",
        "if(opt_parser.close_input_face_mouth):\n",
        "    util.close_input_face_mouth(shape_3d)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e3ba846ee3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'examples/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mopt_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjpg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_alignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaceAlignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_alignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLandmarksType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot detect face landmarks. Exit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/face_alignment/api.py\u001b[0m in \u001b[0;36mget_landmarks\u001b[0;34m(self, image_or_path, detected_faces, return_bboxes, return_landmark_score)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mreturn_landmark_score\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mboolean\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkeypoint\u001b[0m \u001b[0mscores\u001b[0m \u001b[0malong\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkeypoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_landmarks_from_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetected_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_bboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_landmark_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/face_alignment/api.py\u001b[0m in \u001b[0;36mget_landmarks_from_image\u001b[0;34m(self, image_or_path, detected_faces, return_bboxes, return_landmark_score)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_alignment_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_alignment_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_9LmmACg9Mq"
      },
      "source": [
        "## (Optional) Simple manual adjustment to landmarks in case FAN is not accurate, e.g.\n",
        "- slimmer lips\n",
        "- wider eyes\n",
        "- wider mouth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2PLXNlhgztJ"
      },
      "source": [
        "shape_3d[48:, 0] = (shape_3d[48:, 0] - np.mean(shape_3d[48:, 0])) * 1.05 + np.mean(shape_3d[48:, 0]) # wider lips\n",
        "shape_3d[49:54, 1] += 0.           # thinner upper lip\n",
        "shape_3d[55:60, 1] -= 1.           # thinner lower lip\n",
        "shape_3d[[37,38,43,44], 1] -=2.    # larger eyes\n",
        "shape_3d[[40,41,46,47], 1] +=2.    # larger eyes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nlaLLoShR1k"
      },
      "source": [
        "Normalize face as input to audio branch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0GkD0fThN-2"
      },
      "source": [
        "shape_3d, scale, shift = util.norm_input_face(shape_3d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAcGrT3PhY3T"
      },
      "source": [
        "## Step 3: Generate input data for inference based on uploaded audio `MakeItTalk/examples/*.wav`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqh5A_7chQ8g"
      },
      "source": [
        "au_data = []\n",
        "au_emb = []\n",
        "ains = glob.glob1('examples', '*.wav')\n",
        "ains = [item for item in ains if item != 'tmp.wav']\n",
        "ains.sort()\n",
        "for ain in ains:\n",
        "    os.system('ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav'.format(ain))\n",
        "    shutil.copyfile('examples/tmp.wav', 'examples/{}'.format(ain))\n",
        "\n",
        "    # au embedding\n",
        "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
        "    me, ae = get_spk_emb('examples/{}'.format(ain))\n",
        "    au_emb.append(me.reshape(-1))\n",
        "\n",
        "    print('Processing audio file', ain)\n",
        "    c = AutoVC_mel_Convertor('examples')\n",
        "\n",
        "    au_data_i = c.convert_single_wav_to_autovc_input(audio_filename=os.path.join('examples', ain),\n",
        "           autovc_model_path=opt_parser.load_AUTOVC_name)\n",
        "    au_data += au_data_i\n",
        "if(os.path.isfile('examples/tmp.wav')):\n",
        "    os.remove('examples/tmp.wav')\n",
        "\n",
        "# landmark fake placeholder\n",
        "fl_data = []\n",
        "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
        "for au, info in au_data:\n",
        "    au_length = au.shape[0]\n",
        "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
        "    fl_data.append((fl, info))\n",
        "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
        "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
        "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
        "\n",
        "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_fl.pickle'))\n",
        "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))\n",
        "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_au.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_au.pickle'))\n",
        "if (os.path.exists(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))):\n",
        "    os.remove(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))\n",
        "\n",
        "with open(os.path.join('examples', 'dump', 'random_val_fl.pickle'), 'wb') as fp:\n",
        "    pickle.dump(fl_data, fp)\n",
        "with open(os.path.join('examples', 'dump', 'random_val_au.pickle'), 'wb') as fp:\n",
        "    pickle.dump(au_data, fp)\n",
        "with open(os.path.join('examples', 'dump', 'random_val_gaze.pickle'), 'wb') as fp:\n",
        "    gaze = {'rot_trans':rot_tran, 'rot_quat':rot_quat, 'anchor_t_shape':anchor_t_shape}\n",
        "    pickle.dump(gaze, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNzY0KtMhkkV"
      },
      "source": [
        "## Step 4: Audio-to-Landmarks prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP94GnGchXy8"
      },
      "source": [
        "!pwd\n",
        "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
        "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
        "    model.test(au_emb=au_emb)\n",
        "else:\n",
        "    model.test(au_emb=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaYlUNNjnxn"
      },
      "source": [
        "## Step 5: Natural face animation via Image-to-image translation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYBO_czjFSD"
      },
      "source": [
        "fls = glob.glob1('examples', 'pred_fls_*.txt')\n",
        "fls.sort()\n",
        "\n",
        "for i in range(0,len(fls)):\n",
        "    fl = np.loadtxt(os.path.join('examples', fls[i])).reshape((-1, 68,3))\n",
        "    fl[:, :, 0:2] = -fl[:, :, 0:2]\n",
        "    fl[:, :, 0:2] = fl[:, :, 0:2] / scale - shift\n",
        "\n",
        "    if (ADD_NAIVE_EYE):\n",
        "        fl = util.add_naive_eye(fl)\n",
        "\n",
        "    # additional smooth\n",
        "    fl = fl.reshape((-1, 204))\n",
        "    fl[:, :48 * 3] = savgol_filter(fl[:, :48 * 3], 15, 3, axis=0)\n",
        "    fl[:, 48*3:] = savgol_filter(fl[:, 48*3:], 5, 3, axis=0)\n",
        "    fl = fl.reshape((-1, 68, 3))\n",
        "\n",
        "    ''' STEP 6: Imag2image translation '''\n",
        "    model = Image_translation_block(opt_parser, single_test=True)\n",
        "    with torch.no_grad():\n",
        "        model.single_test(jpg=img, fls=fl, filename=fls[i], prefix=opt_parser.jpg.split('.')[0])\n",
        "        print('finish image2image gen')\n",
        "    os.remove(os.path.join('examples', fls[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8mMguI_j1TQ"
      },
      "source": [
        "## Visualize your animation!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmnr2CsChmnB"
      },
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "for ain in ains:\n",
        "  OUTPUT_MP4_NAME = '{}_pred_fls_{}_audio_embed.mp4'.format(\n",
        "    opt_parser.jpg.split('.')[0],\n",
        "    ain.split('.')[0]\n",
        "    )\n",
        "  mp4 = open('examples/{}'.format(OUTPUT_MP4_NAME),'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "\n",
        "  print('Display animation: examples/{}'.format(OUTPUT_MP4_NAME))\n",
        "  display(HTML(\"\"\"\n",
        "  <video width=600 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxWMuEEbpywq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}