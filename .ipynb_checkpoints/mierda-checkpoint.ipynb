{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/albertotrunk/MakeItTalkColabFix/blob/main/quick_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXaL7nU6TEsV",
    "tags": []
   },
   "source": [
    "# MakeItTalk Quick Demo (natural human face animation)\n",
    "\n",
    "- included project setup + pretrained model download\n",
    "- provides step-by-step details\n",
    "- todo: tdlr version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2owgbZ22TQmz"
   },
   "source": [
    "## Preparations\n",
    "- Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yB-ixde4R3nO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ln' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 19 09:59:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 526.98       Driver Version: 526.98       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   43C    P8    13W /  N/A |   3981MiB /  8192MiB |     30%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2748    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      9408    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n",
      "|    0   N/A  N/A      9804    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9820    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      9916    C+G   ...587.49\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     10148    C+G   ...rmouryCrateKeyControl.exe    N/A      |\n",
      "|    0   N/A  N/A     10652    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10736    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10924    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     10932    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11660      C   ...op\\jlab_server\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     14308    C+G   ...8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     14376    C+G   ...p-3.1.7\\GitHubDesktop.exe    N/A      |\n",
      "|    0   N/A  N/A     14508    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     15212    C+G   C:\\JupyterLab\\JupyterLab.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "import subprocess\n",
    "print(subprocess.getoutput('nvidia-smi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o31a6SpeTXDM"
   },
   "source": [
    "- Check ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u4EcdzstSB71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-107243-gbeaf172d75-20220625 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 11.2.0 (crosstool-NG 1.24.0.533_681aaef)\n",
      "  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --disable-w32threads --enable-pthreads --enable-iconv --enable-libxml2 --enable-zlib --enable-libfreetype --enable-libfribidi --enable-gmp --enable-lzma --enable-fontconfig --enable-libvorbis --enable-opencl --disable-libpulse --enable-libvmaf --disable-libxcb --disable-xlib --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-libdav1d --enable-libdavs2 --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librist --enable-libtheora --enable-libvpx --enable-libwebp --enable-lv2 --enable-libmfx --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --disable-vaapi --enable-libvidstab --enable-vulkan --enable-libshaderc --enable-libplacebo --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-ldflags=-pthread --extra-ldexeflags= --extra-libs=-lgomp --extra-version=20220625\n",
      "  libavutil      57. 27.100 / 57. 27.100\n",
      "  libavcodec     59. 34.100 / 59. 34.100\n",
      "  libavformat    59. 25.100 / 59. 25.100\n",
      "  libavdevice    59.  6.100 / 59.  6.100\n",
      "  libavfilter     8. 41.100 /  8. 41.100\n",
      "  libswscale      6.  6.100 /  6.  6.100\n",
      "  libswresample   4.  6.100 /  4.  6.100\n",
      "  libpostproc    56.  5.100 / 56.  5.100\n",
      "Hyper fast Audio and Video encoder\n",
      "usage: ffmpeg [options] [[infile options] -i infile]... {[outfile options] outfile}...\n",
      "\n",
      "Use -h to get full help or, even better, run 'man ffmpeg'\n"
     ]
    }
   ],
   "source": [
    "print(subprocess.getoutput('ffmpeg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taPSDYiSTcM_"
   },
   "source": [
    "- Install Github https://github.com/yzhou359/MakeItTalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4G0XLqo4SofV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'MakeItTalk' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/yzhou359/MakeItTalk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xe5u4Ede-G5"
   },
   "source": [
    "- Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sR4ExzplfBHk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\utils\\MakeItTalkColabFix\\MakeItTalk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'export' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 2)) (4.7.0.68)\n",
      "Requirement already satisfied: face_alignment in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 3)) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: pynormalize in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 6)) (0.1.4)\n",
      "Requirement already satisfied: soundfile in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 7)) (0.12.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 8)) (0.9.2)\n",
      "Requirement already satisfied: pysptk in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
      "Requirement already satisfied: pyworld in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 10)) (0.3.2)\n",
      "Requirement already satisfied: resemblyzer in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from -r requirements.txt (line 11)) (0.1.1.dev0)\n",
      "Requirement already satisfied: future in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from ffmpeg-python->-r requirements.txt (line 1)) (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from opencv-python->-r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from face_alignment->-r requirements.txt (line 3)) (0.19.3)\n",
      "Requirement already satisfied: numba in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from face_alignment->-r requirements.txt (line 3)) (0.56.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from face_alignment->-r requirements.txt (line 3)) (4.64.1)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from face_alignment->-r requirements.txt (line 3)) (1.10.0)\n",
      "Requirement already satisfied: torch in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from face_alignment->-r requirements.txt (line 3)) (1.9.0+cu111)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: mutagen>=1.40.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from pynormalize->-r requirements.txt (line 6)) (1.46.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from soundfile->-r requirements.txt (line 7)) (1.15.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from librosa->-r requirements.txt (line 8)) (5.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from librosa->-r requirements.txt (line 8)) (23.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from librosa->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from librosa->-r requirements.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from librosa->-r requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: cython>=0.28.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from pysptk->-r requirements.txt (line 9)) (0.29.33)\n",
      "Requirement already satisfied: typing in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from resemblyzer->-r requirements.txt (line 11)) (3.7.4.3)\n",
      "Requirement already satisfied: webrtcvad>=2.0.10 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from resemblyzer->-r requirements.txt (line 11)) (2.0.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 7)) (2.21)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from numba->face_alignment->-r requirements.txt (line 3)) (67.3.2)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from numba->face_alignment->-r requirements.txt (line 3)) (6.0.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from numba->face_alignment->-r requirements.txt (line 3)) (0.39.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 8)) (2.28.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from pooch>=1.0->librosa->-r requirements.txt (line 8)) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from torch->face_alignment->-r requirements.txt (line 3)) (4.5.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (2.25.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (2023.2.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (9.4.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from scikit-image->face_alignment->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from tqdm->face_alignment->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->-r requirements.txt (line 8)) (1.26.14)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from importlib-metadata->numba->face_alignment->-r requirements.txt (line 3)) (3.14.0)\n",
      "Requirement already satisfied: tensorboardX in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (2.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from tensorboardX) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from tensorboardX) (23.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from tensorboardX) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "%cd MakeItTalk/\n",
    "!export PYTHONPATH=/content/MakeItTalk:$PYTHONPATH\n",
    "!pip install -r requirements.txt\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AByGGO5fd14P"
   },
   "source": [
    "- Download pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SU4abC3iTmXA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\utils\\MakeItTalkColabFix\\MakeItTalk\\MakeItTalk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (4.6.3)\n",
      "Requirement already satisfied: six in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from gdown) (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests[socks]->gdown) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\alber\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id='1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x' \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id='1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp' \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id='1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu' \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id='1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a' \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access denied with the following error:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id='18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI' \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd ./MakeItTalk/\n",
    "!mkdir examples/dump\n",
    "!mkdir examples/ckpt\n",
    "!pip install --upgrade --no-cache-dir gdown\n",
    "!gdown -O 'examples/ckpt/ckpt_autovc.pth' '1ZiwPp_h62LtjU0DwpelLUoodKPR85K7x'\n",
    "!gdown -O 'examples/ckpt/ckpt_content_branch.pth' '1r3bfEvTVl6pCNw5xwUhEglwDHjWtAqQp'\n",
    "!gdown -O 'examples/ckpt/ckpt_speaker_branch.pth' '1rV0jkyDqPW-aDJcj7xSO6Zt1zSXqn1mu'\n",
    "!gdown -O 'examples/ckpt/ckpt_116_i2i_comb.pth' '1i2LJXKp-yWKIEEgJ7C6cE3_2NirfY_0a'\n",
    "!gdown -O 'examples/dump/emb.pickle' '18-0CYl5E6ungS3H4rRSHjfYvvm-WwjTI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37JeD3ZZdI-a"
   },
   "source": [
    "- prepare your images/audios (or you can use the existing ones)\n",
    "  - An image to animate: upload to `MakeItTalk/examples` folder, image size should be 256x256\n",
    "  - An audio (hopefully no noise) to talk: upload to `MakeItTalk/examples` folder as well\n",
    "\n",
    "## Step 0: import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "olj6VcfiTrd_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"thirdparty/AdaptiveWingLoss\")\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from src.approaches.train_image_translation import Image_translation_block\n",
    "import torch\n",
    "import pickle\n",
    "import face_alignment\n",
    "from src.autovc.AutoVC_mel_Convertor_retrain_version import AutoVC_mel_Convertor\n",
    "import shutil\n",
    "import time\n",
    "import util.utils as util\n",
    "from scipy.signal import savgol_filter\n",
    "from src.approaches.train_audio2landmark import Audio2landmark_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8aaCE6vgmXy"
   },
   "source": [
    "## Step 1: Basic setup for the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "58s-c9H8dWPW"
   },
   "outputs": [],
   "source": [
    "default_head_name = 'paint_boy'           # the image name (with no .jpg) to animate\n",
    "ADD_NAIVE_EYE = True                 # whether add naive eye blink\n",
    "CLOSE_INPUT_FACE_MOUTH = False       # if your image has an opened mouth, put this as True, else False\n",
    "AMP_LIP_SHAPE_X = 2.                 # amplify the lip motion in horizontal direction\n",
    "AMP_LIP_SHAPE_Y = 2.                 # amplify the lip motion in vertical direction\n",
    "AMP_HEAD_POSE_MOTION = 0.7           # amplify the head pose motion (usually smaller than 1.0, put it to 0. for a static head pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRFBOqXMguSH"
   },
   "source": [
    "Default hyper-parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZkZRYLSCf8TK"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--jpg', type=str, default='{}.jpg'.format(default_head_name))\n",
    "parser.add_argument('--close_input_face_mouth', default=CLOSE_INPUT_FACE_MOUTH, action='store_true')\n",
    "\n",
    "parser.add_argument('--load_AUTOVC_name', type=str, default='examples/ckpt/ckpt_autovc.pth')\n",
    "parser.add_argument('--load_a2l_G_name', type=str, default='examples/ckpt/ckpt_speaker_branch.pth')\n",
    "parser.add_argument('--load_a2l_C_name', type=str, default='examples/ckpt/ckpt_content_branch.pth') #ckpt_audio2landmark_c.pth')\n",
    "parser.add_argument('--load_G_name', type=str, default='examples/ckpt/ckpt_116_i2i_comb.pth') #ckpt_image2image.pth') #ckpt_i2i_finetune_150.pth') #c\n",
    "\n",
    "parser.add_argument('--amp_lip_x', type=float, default=AMP_LIP_SHAPE_X)\n",
    "parser.add_argument('--amp_lip_y', type=float, default=AMP_LIP_SHAPE_Y)\n",
    "parser.add_argument('--amp_pos', type=float, default=AMP_HEAD_POSE_MOTION)\n",
    "parser.add_argument('--reuse_train_emb_list', type=str, nargs='+', default=[]) #  ['iWeklsXc0H8']) #['45hn7-LXDX8']) #['E_kmpT-EfOg']) #'iWeklsXc0H8', '29k8RtSUjE0', '45hn7-LXDX8',\n",
    "parser.add_argument('--add_audio_in', default=False, action='store_true')\n",
    "parser.add_argument('--comb_fan_awing', default=False, action='store_true')\n",
    "parser.add_argument('--output_folder', type=str, default='examples')\n",
    "\n",
    "parser.add_argument('--test_end2end', default=True, action='store_true')\n",
    "parser.add_argument('--dump_dir', type=str, default='', help='')\n",
    "parser.add_argument('--pos_dim', default=7, type=int)\n",
    "parser.add_argument('--use_prior_net', default=True, action='store_true')\n",
    "parser.add_argument('--transformer_d_model', default=32, type=int)\n",
    "parser.add_argument('--transformer_N', default=2, type=int)\n",
    "parser.add_argument('--transformer_heads', default=2, type=int)\n",
    "parser.add_argument('--spk_emb_enc_size', default=16, type=int)\n",
    "parser.add_argument('--init_content_encoder', type=str, default='')\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help='learning rate')\n",
    "parser.add_argument('--reg_lr', type=float, default=1e-6, help='weight decay')\n",
    "parser.add_argument('--write', default=False, action='store_true')\n",
    "parser.add_argument('--segment_batch_size', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--emb_coef', default=3.0, type=float)\n",
    "parser.add_argument('--lambda_laplacian_smooth_loss', default=1.0, type=float)\n",
    "parser.add_argument('--use_11spk_only', default=False, action='store_true')\n",
    "parser.add_argument('-f')\n",
    "\n",
    "opt_parser = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qchIUwTTg3AB"
   },
   "source": [
    "## Step 2: load the image and detect its landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SmYcSmrugxQK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PIL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeItTalk/examples/angelina.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m image\u001b[38;5;241m.\u001b[39mshoe()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PIL' is not defined"
     ]
    }
   ],
   "source": [
    "image = PIL.image.load(\"MakeItTalk/examples/angelina.jpg\")\n",
    "image.shoe()\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread('/content/MakeItTalk/examples/morgan.jpg')\n",
    "predictor = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, device='cpu', flip_input=True)\n",
    "shapes = predictor.get_landmarks(img)\n",
    "if (not shapes or len(shapes) != 1):\n",
    "    print('Cannot detect face landmarks. Exit.')\n",
    "    exit(-1)\n",
    "shape_3d = shapes[0]\n",
    "\n",
    "if(opt_parser.close_input_face_mouth):\n",
    "    util.close_input_face_mouth(shape_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_9LmmACg9Mq"
   },
   "source": [
    "## (Optional) Simple manual adjustment to landmarks in case FAN is not accurate, e.g.\n",
    "- slimmer lips\n",
    "- wider eyes\n",
    "- wider mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2PLXNlhgztJ"
   },
   "outputs": [],
   "source": [
    "shape_3d[48:, 0] = (shape_3d[48:, 0] - np.mean(shape_3d[48:, 0])) * 1.05 + np.mean(shape_3d[48:, 0]) # wider lips\n",
    "shape_3d[49:54, 1] += 0.           # thinner upper lip\n",
    "shape_3d[55:60, 1] -= 1.           # thinner lower lip\n",
    "shape_3d[[37,38,43,44], 1] -=2.    # larger eyes\n",
    "shape_3d[[40,41,46,47], 1] +=2.    # larger eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nlaLLoShR1k"
   },
   "source": [
    "Normalize face as input to audio branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0GkD0fThN-2"
   },
   "outputs": [],
   "source": [
    "shape_3d, scale, shift = util.norm_input_face(shape_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAcGrT3PhY3T"
   },
   "source": [
    "## Step 3: Generate input data for inference based on uploaded audio `MakeItTalk/examples/*.wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mqh5A_7chQ8g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "au_data = []\n",
    "au_emb = []\n",
    "ains = glob('examples', '*.wav')\n",
    "ains = [item for item in ains if item != 'tmp.wav']\n",
    "ains.sort()\n",
    "for ain in ains:\n",
    "    os.system('ffmpeg -y -loglevel error -i examples/{} -ar 16000 examples/tmp.wav'.format(ain))\n",
    "    shutil.copyfile('examples/tmp.wav', 'examples/{}'.format(ain))\n",
    "\n",
    "    # au embedding\n",
    "    from thirdparty.resemblyer_util.speaker_emb import get_spk_emb\n",
    "    me, ae = get_spk_emb('examples/{}'.format(ain))\n",
    "    au_emb.append(me.reshape(-1))\n",
    "\n",
    "    print('Processing audio file', ain)\n",
    "    c = AutoVC_mel_Convertor('examples')\n",
    "\n",
    "    au_data_i = c.convert_single_wav_to_autovc_input(audio_filename=os.path.join('examples', ain),\n",
    "           autovc_model_path=opt_parser.load_AUTOVC_name)\n",
    "    au_data += au_data_i\n",
    "if(os.path.isfile('examples/tmp.wav')):\n",
    "    os.remove('examples/tmp.wav')\n",
    "\n",
    "# landmark fake placeholder\n",
    "fl_data = []\n",
    "rot_tran, rot_quat, anchor_t_shape = [], [], []\n",
    "for au, info in au_data:\n",
    "    au_length = au.shape[0]\n",
    "    fl = np.zeros(shape=(au_length, 68 * 3))\n",
    "    fl_data.append((fl, info))\n",
    "    rot_tran.append(np.zeros(shape=(au_length, 3, 4)))\n",
    "    rot_quat.append(np.zeros(shape=(au_length, 4)))\n",
    "    anchor_t_shape.append(np.zeros(shape=(au_length, 68 * 3)))\n",
    "\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_fl_interp.pickle'))\n",
    "if(os.path.exists(os.path.join('examples', 'dump', 'random_val_au.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_au.pickle'))\n",
    "if (os.path.exists(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))):\n",
    "    os.remove(os.path.join('examples', 'dump', 'random_val_gaze.pickle'))\n",
    "\n",
    "with open(os.path.join('examples', 'dump', 'random_val_fl.pickle'), 'wb') as fp:\n",
    "    pickle.dump(fl_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_au.pickle'), 'wb') as fp:\n",
    "    pickle.dump(au_data, fp)\n",
    "with open(os.path.join('examples', 'dump', 'random_val_gaze.pickle'), 'wb') as fp:\n",
    "    gaze = {'rot_trans':rot_tran, 'rot_quat':rot_quat, 'anchor_t_shape':anchor_t_shape}\n",
    "    pickle.dump(gaze, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNzY0KtMhkkV"
   },
   "source": [
    "## Step 4: Audio-to-Landmarks prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WP94GnGchXy8"
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "model = Audio2landmark_model(opt_parser, jpg_shape=shape_3d)\n",
    "if(len(opt_parser.reuse_train_emb_list) == 0):\n",
    "    model.test(au_emb=au_emb)\n",
    "else:\n",
    "    model.test(au_emb=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFaYlUNNjnxn"
   },
   "source": [
    "## Step 5: Natural face animation via Image-to-image translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xYBO_czjFSD"
   },
   "outputs": [],
   "source": [
    "fls = glob.glob1('examples', 'pred_fls_*.txt')\n",
    "fls.sort()\n",
    "\n",
    "for i in range(0,len(fls)):\n",
    "    fl = np.loadtxt(os.path.join('examples', fls[i])).reshape((-1, 68,3))\n",
    "    fl[:, :, 0:2] = -fl[:, :, 0:2]\n",
    "    fl[:, :, 0:2] = fl[:, :, 0:2] / scale - shift\n",
    "\n",
    "    if (ADD_NAIVE_EYE):\n",
    "        fl = util.add_naive_eye(fl)\n",
    "\n",
    "    # additional smooth\n",
    "    fl = fl.reshape((-1, 204))\n",
    "    fl[:, :48 * 3] = savgol_filter(fl[:, :48 * 3], 15, 3, axis=0)\n",
    "    fl[:, 48*3:] = savgol_filter(fl[:, 48*3:], 5, 3, axis=0)\n",
    "    fl = fl.reshape((-1, 68, 3))\n",
    "\n",
    "    ''' STEP 6: Imag2image translation '''\n",
    "    model = Image_translation_block(opt_parser, single_test=True)\n",
    "    with torch.no_grad():\n",
    "        model.single_test(jpg=img, fls=fl, filename=fls[i], prefix=opt_parser.jpg.split('.')[0])\n",
    "        print('finish image2image gen')\n",
    "    os.remove(os.path.join('examples', fls[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8mMguI_j1TQ"
   },
   "source": [
    "## Visualize your animation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xmnr2CsChmnB"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "for ain in ains:\n",
    "  OUTPUT_MP4_NAME = '{}_pred_fls_{}_audio_embed.mp4'.format(\n",
    "    opt_parser.jpg.split('.')[0],\n",
    "    ain.split('.')[0]\n",
    "    )\n",
    "  mp4 = open('examples/{}'.format(OUTPUT_MP4_NAME),'rb').read()\n",
    "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "  print('Display animation: examples/{}'.format(OUTPUT_MP4_NAME))\n",
    "  display(HTML(\"\"\"\n",
    "  <video width=600 controls>\n",
    "        <source src=\"%s\" type=\"video/mp4\">\n",
    "  </video>\n",
    "  \"\"\" % data_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxWMuEEbpywq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "quick_demo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
